{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワーク定義\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer.datasets import split_dataset_random\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainercv.datasets import DirectoryParsingLabelDataset\n",
    "from chainer.datasets import split_dataset_random\n",
    "\n",
    "class MyNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_out):\n",
    "        super(MyNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 32, 3, 3, 1)\n",
    "            self.conv2 = L.Convolution2D(32, 64, 3, 3, 1)\n",
    "            self.conv3 = L.Convolution2D(64, 128, 3, 3, 1)\n",
    "            self.fc4 = L.Linear(None, 1000)\n",
    "            self.fc5 = L.Linear(1000, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, pair):\n",
    "        self.base = pair\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    \n",
    "    def get_example(self, i):\n",
    "        \n",
    "        image, label = self.base[i]\n",
    "        image *= (1.0 / 255.0)\n",
    "        \n",
    "        return (image, label)\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = DirectoryParsingLabelDataset(path)\n",
    "    dataset = PreprocessDataset(dataset)\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    train, test = split_dataset_random(dataset, train_size, seed=0)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from chainer.datasets import cifar\n",
    "# from load_datasets import load_dataset\n",
    "\n",
    "\n",
    "def train(net, batchsize=128, gpu_id=0, max_epoch=5, train_dataset=None, valid_dataset=None, test_dataset=None, postfix='', base_lr=0.01, lr_decay=None):\n",
    "\n",
    "    # 1. Dataset\n",
    "    if train_dataset is None and valid_dataset is None and test_dataset is None:\n",
    "        train, test = load_dataset('./../resize_good_condition/')\n",
    "        # train_size = int(len(train_val) * 0.9)\n",
    "        # train, valid = split_dataset_random(train_val, train_size, seed=0)\n",
    "    else:\n",
    "        train, valid, test = train_dataset, valid_dataset, test_dataset\n",
    "    \n",
    "    #Augument\n",
    "    #train = CIFAR10Augmented(train)\n",
    "    \n",
    "    # 2. Iterator\n",
    "    train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
    "    valid_iter = iterators.MultiprocessIterator(test, batchsize, False, False)\n",
    "\n",
    "    # 3. Model\n",
    "    model = L.Classifier(net)\n",
    "\n",
    "    # 4. Optimizer\n",
    "    optimizer = optimizers.MomentumSGD(lr=base_lr)\n",
    "    optimizer.setup(model)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0005))\n",
    "\n",
    "    # 5. Updater\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "    # 6. Trainer\n",
    "    trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='{}_original_{}result'.format(net.__class__.__name__, postfix))\n",
    "\n",
    "    # 7. Trainer extensions\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.observe_lr())\n",
    "    trainer.extend(extensions.Evaluator(valid_iter, model, device=gpu_id), name='val')\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time', 'lr']))\n",
    "    trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    if lr_decay is not None:\n",
    "        trainer.extend(extensions.ExponentialShift('lr', 0.1), trigger=lr_decay)\n",
    "    trainer.run()\n",
    "    \n",
    "    del trainer\n",
    "\n",
    "    # 8. Evaluation\n",
    "    test_iter = iterators.MultiprocessIterator(test, batchsize, False, False)\n",
    "    test_evaluator = extensions.Evaluator(test_iter, model, device=gpu_id)\n",
    "    results = test_evaluator()\n",
    "    print('Test accuracy:', results['main/accuracy'])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr        \n",
      "\u001b[J1           2.53451     0.128015       2.21566        0.140929           6.55583       0.01        \n",
      "\u001b[J2           3.754       0.126953       2.09829        0.107853           11.4152       0.01        \n",
      "\u001b[J3           2.10493     0.155971       2.13422        0.173295           16.4271       0.01        \n",
      "\u001b[J4           2.72076     0.130757       2.11554        0.140929           21.3235       0.01        \n",
      "\u001b[J5           2.15452     0.125279       2.27431        0.142891           26.1579       0.01        \n",
      "Test accuracy: 0.14289096\n"
     ]
    }
   ],
   "source": [
    "net = train(MyNet(8), gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
