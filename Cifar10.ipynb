{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ネットワークの定義\n",
    "#32＊32\n",
    "import numpy as np\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer.datasets import split_dataset_random\n",
    "from chainer import iterators\n",
    "from chainer import optimizers\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.cuda import to_cpu\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "\n",
    "class MyNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_out):\n",
    "        super(MyNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(None, 32, 3, 3, 1)\n",
    "            self.conv2 = L.Convolution2D(32, 64, 3, 3, 1)\n",
    "            self.conv3 = L.Convolution2D(64, 128, 3, 3, 1)\n",
    "            self.fc4 = L.Linear(None, 1000)\n",
    "            self.fc5 = L.Linear(1000, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.relu(self.conv2(h))\n",
    "        h = F.relu(self.conv3(h))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        h = self.fc5(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Augmented(chainer.dataset.DatasetMixin):\n",
    "\n",
    "    def __init__(self, data, split='train'):\n",
    "        self.data = data \n",
    "        self.split = split\n",
    "        self.random_crop = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        x, t = self.data[i]\n",
    "        if self.split == 'train':\n",
    "            x = x.transpose(1, 2, 0)\n",
    "            h, w, _ = x.shape\n",
    "            x_offset = np.random.randint(self.random_crop)\n",
    "            y_offset = np.random.randint(self.random_crop)\n",
    "            x = x[y_offset:y_offset + h - self.random_crop,\n",
    "                  x_offset:x_offset + w - self.random_crop]\n",
    "            if np.random.rand() > 0.5:\n",
    "                x = np.fliplr(x)\n",
    "            x = x.transpose(2, 0, 1)\n",
    "\n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#学習\n",
    "・ネットワークのオブジェクト\n",
    "・バッチサイズ\n",
    "・使用するGPU ID\n",
    "・学習を終了するエポック数\n",
    "・データセットオブジェクト\n",
    "・学習率の初期値\n",
    "・学習率減衰のタイミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import TransformDataset\n",
    "\n",
    "train_val, test_dataset = cifar.get_cifar10()\n",
    "train_size = int(len(train_val) * 0.9)\n",
    "train_dataset, valid_dataset = split_dataset_random(train_val, train_size, seed=0)\n",
    "\n",
    "\n",
    "# 行いたい変換を関数の形で書く\n",
    "def transform(inputs):\n",
    "    x, t = inputs\n",
    "    x = x.transpose(1, 2, 0)\n",
    "    h, w, _ = x.shape\n",
    "    x_offset = np.random.randint(4)\n",
    "    y_offset = np.random.randint(4)\n",
    "    x = x[y_offset:y_offset + h - 4,\n",
    "          x_offset:x_offset + w - 4]\n",
    "    if np.random.rand() > 0.5:\n",
    "        x = np.fliplr(x)\n",
    "    x = x.transpose(2, 0, 1)\n",
    "\n",
    "    return x, t\n",
    "\n",
    "\n",
    "# 各データをtransformにくぐらせたものを返すデータセットオブジェクト\n",
    "train_dataset = TransformDataset(train_dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from chainer.datasets import cifar\n",
    "\n",
    "\n",
    "def train(network_object, batchsize=128, gpu_id=0, max_epoch=50, train_dataset=None, valid_dataset=None, test_dataset=None, postfix='', base_lr=0.01, lr_decay=None):\n",
    "\n",
    "    # 1. Dataset\n",
    "    if train_dataset is None and valid_dataset is None and test_dataset is None:\n",
    "        train_val, test = cifar.get_cifar10()\n",
    "        train_size = int(len(train_val) * 0.9)\n",
    "        train, valid = split_dataset_random(train_val, train_size, seed=0)\n",
    "    else:\n",
    "        train, valid, test = train_dataset, valid_dataset, test_dataset\n",
    "    \n",
    "    #Augument\n",
    "    #train = CIFAR10Augmented(train)\n",
    "    \n",
    "    \n",
    "    # 2. Iterator\n",
    "    train_iter = iterators.MultiprocessIterator(train, batchsize)\n",
    "    valid_iter = iterators.MultiprocessIterator(valid, batchsize, False, False)\n",
    "\n",
    "    # 3. Model\n",
    "    net = L.Classifier(network_object)\n",
    "\n",
    "    # 4. Optimizer\n",
    "    optimizer = optimizers.MomentumSGD(lr=base_lr).setup(net)\n",
    "    optimizer.add_hook(chainer.optimizer.WeightDecay(0.0005))\n",
    "\n",
    "    # 5. Updater\n",
    "    updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "    # 6. Trainer\n",
    "    trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='{}_cifar10_{}result'.format(network_object.__class__.__name__, postfix))\n",
    "\n",
    "    # 7. Trainer extensions\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.observe_lr())\n",
    "    trainer.extend(extensions.Evaluator(valid_iter, net, device=gpu_id), name='val')\n",
    "    trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'val/main/loss', 'val/main/accuracy', 'elapsed_time', 'lr']))\n",
    "    trainer.extend(extensions.PlotReport(['main/loss', 'val/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "    trainer.extend(extensions.PlotReport(['main/accuracy', 'val/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "    if lr_decay is not None:\n",
    "        trainer.extend(extensions.ExponentialShift('lr', 0.1), trigger=lr_decay)\n",
    "    trainer.run()\n",
    "    \n",
    "    del trainer\n",
    "\n",
    "    # 8. Evaluation\n",
    "    test_iter = iterators.MultiprocessIterator(test, batchsize, False, False)\n",
    "    test_evaluator = extensions.Evaluator(test_iter, net, device=gpu_id)\n",
    "    results = test_evaluator()\n",
    "    print('Test accuracy:', results['main/accuracy'])\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n",
      "(3, 28, 28)\n",
      "epoch       main/loss   main/accuracy  val/main/loss  val/main/accuracy  elapsed_time  lr        \n",
      "\u001b[J1           2.0178      0.262029       1.88099        0.329883           6.34588       0.01        \n",
      "\u001b[J2           1.72345     0.381769       1.74253        0.366211           12.2866       0.01        \n",
      "\u001b[J3           1.58928     0.427261       1.78088        0.351172           17.7303       0.01        \n",
      "\u001b[J4           1.50827     0.454945       1.64144        0.41875            23.9649       0.01        \n",
      "\u001b[J5           1.44606     0.47654        1.69163        0.407617           29.4487       0.01        \n",
      "\u001b[J6           1.39873     0.493963       1.63297        0.415039           35.2336       0.01        \n",
      "\u001b[J7           1.35765     0.508792       1.53903        0.45332            41.302        0.01        \n",
      "\u001b[J8           1.3269      0.52255        1.5446         0.450586           46.7763       0.01        \n",
      "\u001b[J9           1.29221     0.536954       1.48773        0.472656           52.8116       0.01        \n",
      "\u001b[J10          1.2599      0.550859       1.44986        0.490039           58.7917       0.01        \n",
      "\u001b[J11          1.24035     0.557062       1.63729        0.429102           64.1664       0.01        \n",
      "\u001b[J12          1.2176      0.563479       1.4809         0.469336           69.9077       0.01        \n",
      "\u001b[J13          1.19446     0.573242       1.53083        0.462891           76.0055       0.01        \n",
      "\u001b[J14          1.17386     0.579104       1.4373         0.496875           81.6149       0.01        \n",
      "\u001b[J15          1.15405     0.588556       1.44804        0.489844           87.9139       0.01        \n",
      "\u001b[J16          1.14057     0.59286        1.46476        0.494336           93.7897       0.01        \n",
      "\u001b[J17          1.11629     0.603005       1.48217        0.483594           99.7074       0.01        \n",
      "\u001b[J18          1.10588     0.607688       1.49476        0.484961           105.649       0.01        \n",
      "\u001b[J19          1.09194     0.6112         1.43421        0.499219           111.453       0.01        \n",
      "\u001b[J20          1.07896     0.617742       1.42096        0.498047           117.51        0.01        \n",
      "\u001b[J21          1.06514     0.620148       1.49207        0.493945           123.594       0.01        \n",
      "\u001b[J22          1.05001     0.626687       1.50376        0.485156           129.543       0.01        \n",
      "\u001b[J23          1.03535     0.635528       1.46664        0.488867           135.269       0.01        \n",
      "\u001b[J24          1.02173     0.637584       1.46257        0.489844           140.978       0.01        \n",
      "\u001b[J25          1.00967     0.641491       1.45956        0.493945           147.566       0.01        \n",
      "\u001b[J26          0.998116    0.645388       1.43909        0.505859           153.939       0.01        \n",
      "\u001b[J27          0.991771    0.647816       1.43038        0.506836           159.802       0.01        \n",
      "\u001b[J28          0.969239    0.658142       1.41201        0.508203           165.626       0.01        \n",
      "\u001b[J29          0.963507    0.658691       1.41044        0.511328           172.187       0.01        \n",
      "\u001b[J30          0.949588    0.662527       1.39314        0.518945           178.29        0.01        \n",
      "\u001b[J31          0.940452    0.667325       1.44129        0.501562           184.365       0.01        \n",
      "\u001b[J32          0.926548    0.672142       1.37886        0.521484           189.897       0.01        \n",
      "\u001b[J33          0.922293    0.673828       1.44645        0.505078           195.751       0.01        \n",
      "\u001b[J34          0.907399    0.680131       1.35921        0.521484           201.421       0.01        \n",
      "\u001b[J35          0.895613    0.681335       1.3682         0.52207            207.423       0.01        \n",
      "\u001b[J36          0.882518    0.689342       1.3523         0.526367           213.421       0.01        \n",
      "\u001b[J37          0.874786    0.69006        1.43388        0.512305           218.582       0.01        \n",
      "\u001b[J38          0.864001    0.694247       1.4263         0.511719           224.835       0.01        \n",
      "\u001b[J39          0.853481    0.699898       1.34883        0.542969           231.004       0.01        \n",
      "\u001b[J40          0.843467    0.701327       1.37138        0.538867           237.062       0.01        \n",
      "\u001b[J41          0.840744    0.702481       1.36542        0.525781           242.707       0.01        \n",
      "\u001b[J42          0.822772    0.709246       1.3458         0.529102           248.41        0.01        \n",
      "\u001b[J43          0.816581    0.711337       1.40569        0.525391           253.793       0.01        \n",
      "\u001b[J44          0.80853     0.713675       1.40437        0.520898           259.633       0.01        \n",
      "\u001b[J45          0.802305    0.717973       1.38376        0.542969           265.235       0.01        \n",
      "\u001b[J46          0.792671    0.719373       1.36634        0.5375             270.939       0.01        \n",
      "\u001b[J47          0.78529     0.721524       1.39983        0.532617           276.493       0.01        \n",
      "\u001b[J48          0.772158    0.728165       1.37404        0.536133           282.377       0.01        \n",
      "\u001b[J49          0.763512    0.72927        1.41512        0.524219           288.293       0.01        \n",
      "\u001b[J50          0.757481    0.731534       1.36918        0.543164           294.426       0.01        \n",
      "Test accuracy: 0.5416337\n"
     ]
    }
   ],
   "source": [
    "net = train(MyNet(10), gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
